\section{Experiments}\label{sec:experiments}

We train a baseline model for image classification on the CIFAR-100 dataset with ResNet-50~\cite{resnet50} following~\cite{cifar100params}, saving checkpoints every 10 epochs. From each checkpoint we train $4$ new models with different optimizer settings, for details see Appendix Tables~\ref{tab:optimizer_perturbations} and~\ref{tab:hyperparams_baseline}. All models are trained to convergence, with the best validation scored model saved for experiments, as shown in Figure~\ref{fig:evolution}. A total of $4$ variants and $26$ branch points were trained, yielding $104$ related models and $5,356$ binary souping combinations for analysis. Additionally, we train 12 baseline models with and without Stochastic Weight Averaging (SWA) to compare the depth of fine-tuning paths against the breadth of SWA, see Appendix~\ref{appendix:SWA_results}.

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.8\linewidth]{./figures/branching_models.drawio.pdf}
    \caption{Branching of fine-tuned models from baseline checkpoints. A single baseline model is trained, with checkpoints saved every 10 epochs. From each checkpoint, 4 variants are trained with different optimizer hyper-parameter perturbations.}\label{fig:evolution}
    % \Description{A diagram showing the branching of fine-tuned models from baseline checkpoints. A single baseline model is trained, with checkpoints saved every 10 epochs. From each checkpoint, 4 variants are trained with different optimizer hyper-parameter perturbations.}
\end{figure}

% Our experiments are designed to recreate the effect of different fine-tuning trajectories, but with varying diversity of pre-trained model and length of fine-tuning.

\subsection{Soup Gain and Shared Epochs}

% We group the soups by the number of shared epochs between the two ingredients before they diverge into different training trajectories. For example, a pair of models branched form the baseline at epoch 50 and 100 respectively share 50 epochs. In Figure~\ref{fig:soup_gain_quantiles}, we observe the distribution of soup gains shifts positively as the number of shared epochs increases. However, the soup gain is often large and negative until around epoch 150. After epoch 250, nearly all soups are approximately neutral.


% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.8\linewidth]{./figures/soup_gain_quantiles_vs_shared_epochs.pdf}
%     % \Description{A line plot figure showing quantiles of soup gain against shared epochs.}
%     \caption{Quantiles of soup gain vs shared epochs. 
%     % As the number of shared epochs increases, the distribution of soup gains shifts positively. However, the median soup gain is negative until around 150 shared epochs. After 250 shared epochs, nearly all soups are approximately neutral.
%     }\label{fig:soup_gain_quantiles}

% \end{figure}
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.8\linewidth]{./figures/combined_prob_and_conditional_gain.pdf}
%       % \Description{A line plot figure showing probability of positive soup gain and expected soup gain given positive soup gain against shared epochs.}
%     \caption{Probability of positive soup gain and expected soup gain given positive soup gain vs shared epochs. 
%     % As shared epochs increases, the probability of positive soup gain increases, reaching around $80\%$ after 250 shared epochs. The expected soup gain given positive soup gain is relatively flat at around 0.5\% accuracy improvement, decreasing to around 0.2\% at high shared epochs.
%     }\label{fig:prob_and_conditional_gain}  

% \end{figure}

% \begin{figure}[ht]
%   \centering
%   \begin{minipage}[t]{0.48\linewidth}
%     \centering
%     \includegraphics[width=\linewidth]{./figures/soup_gain_quantiles_vs_shared_epochs.pdf}
%     \caption{Quantiles of soup gain vs shared epochs.}
%     \label{fig:soup_gain_quantiles}
%   \end{minipage}\hfill
%   \begin{minipage}[t]{0.48\linewidth}
%     \centering
%     \includegraphics[width=\linewidth]{./figures/combined_prob_and_conditional_gain.pdf}
%     \caption{Probability of positive soup gain and conditional expected gain vs shared epochs.}
%     \label{fig:prob_and_conditional_gain}
%   \end{minipage}
% \end{figure}

Figure~\ref{fig:soup_gain_cdf} shows the cumulative distribution function (CDF) of soup gains. Many soups have extreme behaviour, with $40\%$ of soups losing over $60\%$ and only $14\%$ with positive gain. There is also a sharp transition to collapse, with only $15\%$ soups between $-70\%$ and $-20\%$ gain. Figure~\ref{fig:soup_gain_probabilities} groups soups by the number of shared training epochs between ingredients (e.g., ingredients branched at epochs 50 and 100 share 50 epochs). We observe that the probability of positive soup gain generally increases with shared epochs, reaching around $80\%$ after 260 shared epochs. At this stage, almost no soups drop accuracy by more than $5\%$. However, peak gains $(>0.5\%)$ require a balance; if shared training is too extensive ingredients are not diverse enough, performance diminishes. Further analysis of the distribution of soups gains over shared epochs on mean gain, loss metrics, and model collapse is provided in Appendices~\ref{fig:soup_gain_conditional_exp}, ~\ref{fig:soup_gain_quantiles_loss} and~\ref{fig:model_collapse}.
 
\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{./figures/prob_acc_gain_vs_shared_epochs_cdf.pdf}
  \caption{Empirical CDF of soup gain over all soups.}
  \label{fig:soup_gain_cdf}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{./figures/prob_acc_gain_vs_shared_epochs_contours.pdf}
  \caption{Probability of soup gain being greater than $k\%$ for varying $k$ with 95\% CIs.}
  \label{fig:soup_gain_probabilities}
\end{figure}



% To better illustrate how much souping helps, we plot the probability of positive soup gain and the average soup gain in accuracy for such positive soups in Figure~\ref{fig:prob_and_conditional_gain}.The probability of positive soup gain increases with shared epochs, reaching around $80\%$ after 250 shared epochs. The conditional expected soup gain is noisy, at around 0.5\% accuracy improvement when souping works. Towards the upper end of shared epochs, the gains decrease to around 0.2\%. This suggests that while souping becomes more likely to work with increased shared training, the magnitude of gain decreases when the models are too similar.


\subsection{Predicting Soupability with Similarity}

To test if soupability is predictable, we compute a variety of similarity and distance metrics between model pairs. All metrics perform similarly, as seen in Figure~\ref{fig:soup_gain_vs_all_metrics}. We plot the KL divergence between the outputs of the ingredients as a representative example in Figure~\ref{fig:soup_gain_vs_kl_logits} and find a strong negative correlation with soup gain (Spearman $-0.86$), indicating divergence often leads to model collapse. However, among positive soups, soup gain has a moderate positive correlation with dissimilarity (Spearman 0.39), see Figure~\ref{fig:soup_gain_vs_kl_positive_soups}. Effective souping requires models to be sufficiently similar, but also rewards variety. Balancing these two effects is key to tasty soups. Additionally, shared epochs correlate strongly with all similarity metrics, for example (Spearman $-0.67$) with KL divergence. More details can be found in Appendix~\ref{fig:kl_shared_epochs}.

% This includes the l2 distance and cosine similarity on a vector of the model parameters, the Kullback-Leibler (KL) divergence between the output logits on the test set, the mean squared error (MSE) between the output logits on the test set, and the Centered Kernel Alignment (CKA)~\citep{SimilarityCKA} between the logits and the penultimate layer activations on the test set. 



\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{./figures/soup_gain_vs_kl.png}
  \caption{KL vs soup gain (Spearman $-0.86$).}
  \label{fig:soup_gain_vs_kl_logits}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{./figures/soup_gain_vs_kl_positive_soups.png}
  \caption{KL vs $(+)$ soup gain (Spearman $0.39$).}
  \label{fig:soup_gain_vs_kl_positive_soups}
\end{figure}




\subsection{Is Souping Transitive?}

To test the hypothesis that soupable models reside in the same low-loss basin, we evaluate the transitivity of model triplets $(A, B, C)$. Figure~\ref{fig:transitivity} shows that $B$ and $C$ are highly likely to soup only if $A$ soups with both $B$ and $C$. We observe a moderate positive correlation (Spearman $0.64$) between the gain of $(B,C)$ and the minimum gain of $(A, B)$ and $(A, C)$, see Figure~\ref{fig:transitivity_min}. We attempt to explain when transitivity fails in terms of the branching epochs of the vertices of a given triple, but find no clear pattern. See Appendix Tables~\ref{tab:shared_epoch_triples_transitivity} and~\ref{tab:epoch_diff_triples_transitivity}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{./figures/transitivity_binary.pdf}
  \caption{Probability of positive soup gain of $B$ and $C$ vs positive soups with $A$.}
  \label{fig:transitivity}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{./figures/model_embeddings.pdf}
  \caption{2D embedding of 104 models using soup-gain distance; edges indicate $(+)$ soups.}
  \label{fig:model_embedding}
\end{figure}


We embed our $104$ models into 2D using soup gain as a distance metric to search for souping clusters, plotting them in Figure~\ref{fig:model_embedding}, with details found in Section~\ref{sec:model_embedding_creation}. We find all most successful soups form the edges of a single connected component of models, while there is a single dense cluster of models which are largely branched from later on in the training procedure. There are many counter-examples, but this supports the conclusion that souping is moderately transitive and successful ingredients generally lie within a single loss basin.

\subsection{Souping for Robustness to Corruption}

% All experiments thus far have measured soup gain on a held-out test set. However one of our primary motivations is robustness to distribution shift~\citep{seasoningsoups}. 
To establish whether souping for in-distribution (ID) performance also increases out-of-distribution (OOD) performance, we compute the soup gain on CIFAR-100C~\citep{cifar100c} with severity level 3. The soup gains on test and corrupted data correlate strongly (Spearman $0.99$), even when restricted to positive soups (Pearson $0.61$), see Figures~\ref{fig:test_vs_corrupted},~\ref{fig:test_vs_corrupted_pos}. Thus, ID performance improvement can transfer to unseen target distributions.

We also plot the probability of positive soup gain on corrupted data as a function of shared epochs in Figure~\ref{fig:soup_corrupted_positive_gain_prob}. The probability of positive gain increases with the number of shared epochs for both clean and corrupted data but the corrupted data always has a lower probability of positive gain.

\subsection{How does souping compare to SWA?}
Model accuracy on both clean and corrupted data has been shown to improve with souping. 
Here we compare the improvements of souping to SWA in Tab. \ref{tab:swa_compare}. SWA offers a significant boost in robustness to shift, always improves the baseline run, and performs better than our best geometric mean soups. We hypothesize that in this experimental setting, SWA has explored a wider breadth of points in the low loss basin than possible with just two ingredients and has more closely converged to the low-loss center described by \citet{modelstock}. More carefully selecting ingredients for a soup, either through greedy souping with more models~\cite{soups} or by using a more sophisticated weighting scheme~\cite{seasoningsoups} may reduce the gap.

\begin{table}[t]
\centering
\small
\begin{tabular}{lccc}
\toprule
Type &
\makecell{P(Gain\\$>0$)} &
\makecell{Mean Gain\\(Acc \%)} &
\makecell{Mean Corrupted\\Gain (Acc \%)} \\
\midrule
Soups: 200 & $43.6\% \pm 7.7\%$ & $0.6\% \pm 0.04\%$ & $0.71\% \pm 0.09\%$ \\
Soups: 250 & $51.2\% \pm 9.9\%$ & $0.16\% \pm 0.04\%$ & $0.05\% \pm 0.08\%$ \\
SWA (12) & $100\%$ & $1.6\% \pm 0.3\%$ & $3.7\% \pm 0.4\%$ \\
\bottomrule
\end{tabular}
\caption{Comparison of souping robustness to SWA.}
\label{tab:swa_compare}
\end{table}




%  We test whether souping can help reduce the gap between the test set and corrupted set loss, or \emph{robustness gap}. The mean and median difference in robustness gap before and after souping is approximately 0, indicating that souping does not improve this gap, see the CDF plotted in Figure~\ref{fig:soup_robustness_cdf}.