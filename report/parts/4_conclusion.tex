\section{Conclusion}

In this work, we have conducted a series of experiments to further our understanding of souping. We find that souping is more effective when models share more training epochs before diverging into different training trajectories. This suggests that shared training is necessary to reach a common low-loss basin. However, too many shared epochs and the soup gain is minimal. We also find that various similarity measures between models correlate similarly with soup gain. More similar models are less likely to collapse when souped, but also yield smaller soup gains. Thus, the right balance must be struck for the most effective souping. When souping, we encourage practitioners to test a range of similarities of ingredients to ensure they are finding an optimal soup. Our experiments showing that souping is mostly transitive support the low-loss basin hypothesis. Finally, we find that soup gains on in-distribution data are strongly correlated with those on corrupted data.

\textbf{Limitations}: While our experiments provide insight into souping, they are limited in scope. We only consider one dataset (CIFAR-100), one architecture (ResNet-50) with one baseline training trajectory. It is possible that our findings do not generalise to other datasets or architectures. Additionally, we only consider pairwise souping using the arithmetic mean at the midpoint. Other methods of souping, such as learned soups, may yield different results.

\textbf{Future Work}: Future empirical work could conduct similar experiments in different settings, such as a variety of model architectures and datasets. It could also center on comparing souping with other methods of weight averaging such as SWA. Theory could be developed for souping in simpler settings like an overparameterized linear model or a shallow network. Theory could also be created to help characterise the noise reduction and consequently the reduction in loss we expect from souping.

\subsection*{Open Code and Data }
The source code and data generation for this project can be found at \href{Too-Salty}{https://github.com/chipnbits/too-salty} .